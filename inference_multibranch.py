# -*- coding: utf-8 -*-
"""Inference_Multibranch.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1S6Q8GkFP2P2cr-AT6D71eXToueaZ2pTV
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import cv2 as cv
import matplotlib.pyplot as plt
from PIL import Image
import os
import pickle
import glob
import random
import itertools
import copy
import math
from skimage import color
from sklearn.metrics import accuracy_score
from torch.utils.data import Dataset
from torchvision import datasets
from torchvision.transforms import ToTensor
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
from sklearn.metrics import classification_report
from sklearn.neighbors import KNeighborsClassifier
import torch
import torch.optim as optim
import torch.nn as nn
import torch.nn.functional as F
from sklearn.metrics import confusion_matrix
import seaborn as sns
import csv
import pandas as pd
from sklearn.model_selection import train_test_split

parser = argparse.ArgumentParser(description='PyTorch Inference')
parser.add_argument('data', metavar='DIR', default='/content/drive/My Drive/Colab Notebooks/FlixStock/classification-assignment.zip (Unzipped Files)/classification-assignment/images/')
parser.add_argument('weights', default='/content/drive/My Drive/Colab Notebooks/FlixStock/classification-assignment.zip (Unzipped Files)/classification-assignment/Multilabel.pth')
parser.add_argument('attributes', default='/content/drive/My Drive/Colab Notebooks/FlixStock/classification-assignment.zip (Unzipped Files)/classification-assignment/attributes_test.csv')
args = parser.parse_args()

filenames_train=glob.glob(args.data+'*')
filenames_train=sorted(filenames_train)
filenames_train=sorted(filenames_train,key=len)

len(filenames_train)

class FlixStockDataset(Dataset):
    def __init__(self, filenames, transform=None):#, target_transform=None):
        self.transform = transform
        self.filenames=filenames

    def __len__(self):
        return len(self.filenames)

    def __getitem__(self, idx):
        image = Image.open('/content/drive/My Drive/Colab Notebooks/FlixStock/classification-assignment.zip (Unzipped Files)/classification-assignment/images/'+self.filenames[idx])
        image=image.convert('RGB')
        if self.transform:
            sample = self.transform(image)
        dict_data = {
            'img': sample
        }
        return dict_data, self.filenames[idx]

transform = transforms.Compose([transforms.Resize((300,225)),
                                transforms.ToTensor(),
                                transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                                  std=[0.229, 0.224, 0.225])])

transform_train = transforms.Compose([
    transforms.Resize((300,225)),
    transforms.RandomHorizontalFlip(),
    transforms.ColorJitter(brightness=.5, hue=.5, saturation=.5, contrast=.5),
    transforms.RandomRotation(20),
    transforms.RandomAffine(degrees=20, translate=(0.1, 0.1), scale=(0.8, 1.2),
                            shear=None, fill=(255, 255, 255)),
    transforms.RandomPerspective(distortion_scale=0.5),
    transforms.GaussianBlur(5),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                              std=[0.229, 0.224, 0.225])
])


transform_label = transforms.Compose([transforms.ToTensor()])

test_dataset = FlixStockDataset(X_test, transform=transform)#, target_transform=transform_label)

test_loader = DataLoader(test_dataset, batch_size=16,
                        shuffle=False, num_workers=0)

class_weights={'pattern':[1/i for i in np.bincount(np.array(y_train,dtype='int64')[:,0])], 'sleeve_length':[1/i for i in np.bincount(np.array(y_train,dtype='int64')[:,1])], 'neck_type':[1/i for i in np.bincount(np.array(y_train,dtype='int64')[:,2])]}

import torchvision.models as models
class MultiOutputModel(nn.Module):
    def __init__(self, patterns, sleeve_types, neck_types):
        super().__init__()
        # self.base_model = models.vgg16_bn(pretrained=True)
        self.conv1 = nn.Conv2d(3, 6, 5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.pattern = nn.Sequential(
            nn.Dropout(p=0.2),
            nn.Linear(in_features=61056, out_features=1000),
            nn.Dropout(p=0.2),
            # nn.Linear(in_features=6000, out_features=1000),
            nn.Linear(in_features=1000, out_features=patterns)
        )
        self.sleeve_length = nn.Sequential(
            nn.Dropout(p=0.2),
            nn.Linear(in_features=61056, out_features=1000),
            nn.Dropout(p=0.2),
            # nn.Linear(in_features=6000, out_features=1000),
            nn.Linear(in_features=1000, out_features=sleeve_types)
        )
        self.neck_type = nn.Sequential(
            nn.Dropout(p=0.2),
            nn.Linear(in_features=61056, out_features=1000),
            nn.Dropout(p=0.2),
            # nn.Linear(in_features=6000, out_features=1000),
            nn.Linear(in_features=1000, out_features=neck_types)
        )
    def forward(self, x):
        # for param in self.base_model.features.parameters():
        #     param.require_grad = False
        # print(x.shape)
        x = self.pool(F.tanh(self.conv1(x)))
        x = self.pool(F.tanh(self.conv2(x)))
        # print(x.shape)
        # x = self.pool(x)
        x = torch.flatten(x, start_dim=1)
        print(self.pattern(x).shape)
        return {
            'pattern': self.pattern(x),
            'sleeve_length': self.sleeve_length(x),
            'neck_type': self.neck_type(x)
        }


    def get_loss(self, net_output, ground_truth, class_weights):#gamma=2, alpha=0.25):
        pattern_loss = F.cross_entropy(net_output['pattern'], ground_truth['pattern'].long(), torch.FloatTensor(class_weights['pattern']))
        sleeve_length_loss = F.cross_entropy(net_output['sleeve_length'], ground_truth['sleeve_length'].long(), torch.FloatTensor(class_weights['sleeve_length']))
        neck_type_loss = F.cross_entropy(net_output['neck_type'], ground_truth['neck_type'].long(), torch.FloatTensor(class_weights['neck_type']))
        # focal_loss1 = (alpha * (1-torch.exp(-pattern_loss))**gamma * pattern_loss).mean()
        # focal_loss2 = (alpha * (1-torch.exp(-sleeve_length_loss))**gamma * sleeve_length_loss).mean()
        # focal_loss3 = (alpha * (1-torch.exp(-neck_type_loss))**gamma * neck_type_loss).mean()
        loss = pattern_loss + sleeve_length_loss + neck_type_loss
        return loss, {'pattern': pattern_loss, 'sleeve_length': sleeve_length_loss, 'neck_type': neck_type_loss}

N_epochs = 50
batch_size = 16
 
model = MultiOutputModel(patterns=7, sleeve_types=4, neck_types=10)
optimizer = torch.optim.Adam(model.parameters())
# criterion = nn.BCEWithLogitsLoss()

model.load_state_dict(torch.load('/content/drive/My Drive/Colab Notebooks/FlixStock/classification-assignment.zip (Unzipped Files)/classification-assignment/Multibranch.pth'))

from sklearn.metrics import confusion_matrix
import pandas as pd
import seaborn as sns
x=[]
with torch.no_grad():
    for data in test_loader:
        img_dict, index = data
        outputs = model(img_dict['img'])
        _, predicted_pattern = torch.max(outputs['pattern'].data, 1)
        _, predicted_sleeve_type = torch.max(outputs['sleeve_length'].data, 1)
        _, predicted_neck_type = torch.max(outputs['neck_type'].data, 1)
        for i in range(len(index)):
            x.append([index[i],predicted_pattern[i],predicted_sleeve_type[i],predicted_neck_type[i]])

            lab_patt.extend([int(i) for i in img_dict['labels']['pattern']])
            pred_sleeve.extend([i for i in predicted_sleeve_type])
            lab_sleeve.extend([int(i) for i in img_dict['labels']['sleeve_length']])
            pred_neck.extend([i for i in predicted_neck_type])
            lab_neck.extend([int(i) for i in img_dict['labels']['neck_type']])

with open(args.output, "w", newline="") as f:
    writer = csv.writer(f)
    writer.writerows(x)

