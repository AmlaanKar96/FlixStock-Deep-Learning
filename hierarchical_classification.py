# -*- coding: utf-8 -*-
"""Hierarchical_Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Y-t3VxkZxuXcOtoJK3CrJ2qyBlq1OQ2l
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import cv2 as cv
import matplotlib.pyplot as plt
from PIL import Image
import os
import pickle
import glob
import random
import itertools
import copy
import math
from skimage import color
from sklearn.metrics import accuracy_score
from torch.utils.data import Dataset
from torchvision import datasets
from torchvision.transforms import ToTensor
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
from sklearn.metrics import classification_report
from sklearn.neighbors import KNeighborsClassifier
import torch
import torch.optim as optim
import torch.nn as nn
import torch.nn.functional as F
from sklearn.metrics import confusion_matrix
import seaborn as sns
import csv
import pandas as pd
from sklearn.model_selection import train_test_split

parser = argparse.ArgumentParser(description='PyTorch Training')
parser.add_argument('data', metavar='DIR', default='/content/drive/My Drive/Colab Notebooks/FlixStock/classification-assignment.zip (Unzipped Files)/classification-assignment/images/')
parser.add_argument('attributes', default='/content/drive/My Drive/Colab Notebooks/FlixStock/classification-assignment.zip (Unzipped Files)/classification-assignment/attributes.csv')
args = parser.parse_args()

filenames_train=glob.glob(args.data+'*')
filenames_train=sorted(filenames_train)
filenames_train=sorted(filenames_train,key=len)

len(filenames_train)

df=pd.read_csv(args.attributes)
df

df=df.values
len(df)

df_dict,dtset,labels,dtset_dict={},[],[],{}
for i in df:
    df_dict[i[0]]=i
for i in filenames_train:
    ret=i.split('/')[-1]
    try:
        ret1=df_dict[ret]
        try:
            ret1=int(df_dict[ret][1])
            ret2=int(df_dict[ret][2])
            ret3=int(df_dict[ret][3])
            dtset.append(df_dict[ret][0])
            labels.append([df_dict[ret][1],df_dict[ret][2],df_dict[ret][3]])
            try:
                ret4=dtset_dict[ret1]
            except:
                dtset_dict[ret1]={}
            try:
                ret4=dtset_dict[ret1][ret2]
            except:
                dtset_dict[ret1][ret2]={}
            try:
                dtset_dict[ret1][ret2][ret3]+=1
            except:
                dtset_dict[ret1][ret2][ret3]=1
        except:
            pass
    except:
        pass

dtset_dict

df_dict,dtset,labels,dtset_dict={},[],[],{}
for i in df:
    df_dict[i[0]]=i
for i in filenames_train:
    ret=i.split('/')[-1]
    try:
        ret1=df_dict[ret]
        try:
            ret1=df_dict[ret][1]
            ret2=df_dict[ret][2]
            ret3=df_dict[ret][3]
            try:
                try:
                    ret1=int(ret1)
                except:
                    try:
                        if int(ret2)!=3:
                            ret1=6
                            ret3=9
                        else:
                            try:
                                if int(ret3)!=9:
                                    ret1=6
                                else:
                                    continue
                            except:
                                continue
                    except:
                        try:
                            if int(ret3)!=9:
                                ret1=6
                                ret2=3
                            else:
                                continue
                        except:
                            continue
                ret4=dtset_dict[ret1]
            except:
                dtset_dict[ret1]={}
            try:
                try:
                    ret2=int(ret2)
                except:
                    try:
                        if int(ret1)!=6:
                            ret2=3
                            ret3=9
                        else:
                            try:
                                if int(ret3)!=9:
                                    ret2=3
                                else:
                                    continue
                            except:
                                continue
                    except:
                        continue
                ret4=dtset_dict[ret1][ret2]
            except:
                dtset_dict[ret1][ret2]={}
            try:
                try:
                    ret3=int(ret3)
                except:
                    try:
                        if int(ret1)!=6:
                            ret3=9
                            ret2=3
                        else:
                            try:
                                if int(ret2)!=3:
                                    ret3=9
                                else:
                                    continue
                            except:
                                continue
                    except:
                        continue
                dtset_dict[ret1][ret2][ret3]+=1
            except:
                dtset_dict[ret1][ret2][ret3]=1
            dtset.append(df_dict[ret][0])
            labels.append([ret1,ret2,ret3])
        except:
            pass
    except:
        pass

dtset_dict

X_train, X_test, y_train, y_test = train_test_split(dtset, labels, test_size=0.1, random_state=42)

class NeckDataset(Dataset):
    def __init__(self, filenames, label_dict, transform1=None, transform2=None, res=None):#, target_transform=None):
        self.transform1 = transform1
        self.transform2 = transform2
        self.filenames=filenames
        self.label_dict=label_dict
        self.res=res

    def __len__(self):
        return len(self.filenames)

    def __getitem__(self, idx):
        image = Image.open('/content/drive/My Drive/Colab Notebooks/FlixStock/classification-assignment.zip (Unzipped Files)/classification-assignment/images/'+self.filenames[idx])
        image=image.convert('RGB')
        label=self.label_dict[idx]#[1:]
        if self.res==1:
            if self.transform1:
                sample = self.transform1(image)
        elif self.transform1 and label==0:
            sample = self.transform1(image)
        else:
            sample = self.transform2(image)
        dict_data = {
            'img': sample,
            'labels': label
        }
        return dict_data, idx

class TestDataset(Dataset):
    def __init__(self, filenames, label_dict, transform=None):#, target_transform=None):
        self.transform = transform
        # self.target_transform = target_transform
        self.filenames=filenames
        self.label_dict=label_dict

    def __len__(self):
        return len(self.filenames)

    def __getitem__(self, idx):
        image = Image.open('/content/drive/My Drive/Colab Notebooks/FlixStock/classification-assignment.zip (Unzipped Files)/classification-assignment/images/'+self.filenames[idx])
        image=image.convert('RGB')
        label=self.label_dict[idx]#[1:]
        if self.transform:
            sample = self.transform(image)
        dict_data = {
            'img': sample,
            'labels': {
                'pattern': label[0],
                'sleeve_length': label[1],
                'neck_type': label[2]
            }
        }
        return dict_data, idx

transform = transforms.Compose([transforms.ToTensor(),
                                transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                                  std=[0.229, 0.224, 0.225])])

transform_train = transforms.Compose([
    transforms.RandomHorizontalFlip(),
    transforms.ColorJitter(brightness=.5, hue=.5, saturation=.5, contrast=.5),
    transforms.RandomRotation(20),
    transforms.RandomAffine(degrees=20, translate=(0.1, 0.1), scale=(0.8, 1.2),
                            shear=None, fill=(255, 255, 255)),
    transforms.RandomPerspective(distortion_scale=0.5),
    transforms.GaussianBlur(5),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                              std=[0.229, 0.224, 0.225])
])


transform_label = transforms.Compose([transforms.ToTensor()])

def create_train_loader(only,label_type,label_val,label_type1=None,label_val1=None,label_type2=None):
    neck_train,neck_train_y,neck_test,neck_test_y=[],[],[],[]
    if only==0:
        for i in range(len(y_train)):
            neck_train.append(X_train[i])
            if y_train[i][label_type]==label_val:
                neck_train_y.append(1)
            else:
                neck_train_y.append(0)
        train_dataset_neck = NeckDataset(neck_train, neck_train_y, transform1=transform_train, transform2=transform, res=0)

    elif only==1:
        for i in range(len(y_train)):
            if y_train[i][label_type]!=label_val:
                neck_train.append(X_train[i])
                neck_train_y.append(y_train[i][label_type])
        train_dataset_neck = NeckDataset(neck_train, neck_train_y, transform1=transform_train, transform2=transform, res=1)

    else:
        for i in range(len(y_train)):
            if y_train[i][label_type]==label_val and y_train[i][label_type1]==label_val1:
                neck_train.append(X_train[i])
                neck_train_y.append(y_train[i][label_type2])
        train_dataset_neck = NeckDataset(neck_train, neck_train_y, transform1=transform_train, transform2=transform, res=1)

    return DataLoader(train_dataset_neck, batch_size=32, shuffle=True, num_workers=0),neck_train_y

train_loader_neck, neck_train_y = create_train_loader(0,2,9)
train_loader_only_neck, only_neck_train_y = create_train_loader(1,2,9)
train_loader_sleeve, sleeve_train_y = create_train_loader(0,1,3)
train_loader_only_sleeve, only_sleeve_train_y = create_train_loader(1,1,3)
train_loader_only_pattern, only_pattern_train_y = create_train_loader(2,1,3,2,9,0)

test_dataset = TestDataset(X_test, y_test, transform=transform)
test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)

train_dataset = TestDataset(X_train, y_train, transform=transform)
train_loader = DataLoader(train_dataset, batch_size=1, shuffle=False, num_workers=0)

import torchvision.models as models
class HierModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 6, 5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(61056, 1200)
        self.fc2 = nn.Linear(1200, 120)
        self.fc_neck = nn.Linear(120, 2)
        self.fc_only_neck = nn.Linear(120, 9)
        self.fc_sleeve = nn.Linear(120, 2)
        self.fc_only_sleeve = nn.Linear(120, 3)
        self.fc_only_pattern = nn.Linear(120, 7)

    def forward(self, x, ret):
        x = self.pool(F.tanh(self.conv1(x)))
        x = self.pool(F.tanh(self.conv2(x)))
        x = torch.flatten(x, 1)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        if ret is 'Neck':
            x = self.fc_neck(x)
        elif ret is 'Only_Neck':
            x = self.fc_only_neck(x)
        elif ret is 'Sleeve':
            x = self.fc_sleeve(x)
        elif ret is 'Only_Sleeve':
            x = self.fc_only_sleeve(x)
        elif ret is 'Only_Pattern':
            x = self.fc_only_pattern(x)
        return x

def test_epoch(loader,stri):
    correct1, correct2, correct3 = 0, 0, 0
    total1, total2, total3 = 0, 0, 0
    pred_patt,lab_patt=[],[]
    pred_sleeve,lab_sleeve=[],[]
    pred_neck,lab_neck=[],[]
    patt,slee,ne=-1,-1,-1
    with torch.no_grad():
        for data in loader:
            ret=0
            img_dict, index = data
            outputs = model(img_dict['img'],'Neck')
            _, predicted_neck_type = torch.max(outputs.data, 1)
            if predicted_neck_type[0]!=1:
                pred_patt.append(6)
                patt=6
                lab_patt.extend([int(i) for i in img_dict['labels']['pattern']])
                pred_sleeve.append(3)
                slee=3
                lab_sleeve.extend([int(i) for i in img_dict['labels']['sleeve_length']])
                outputs = model(img_dict['img'],'Only_Neck')
                _, predicted_neck_type = torch.max(outputs.data, 1)
                pred_neck.extend([i for i in predicted_neck_type])
                ne=predicted_neck_type[0]
                lab_neck.extend([int(i) for i in img_dict['labels']['neck_type']])
                ret=1
            if ret==0:
                pred_neck.append(9)
                ne=9
                lab_neck.extend([int(i) for i in img_dict['labels']['neck_type']])

                outputs = model(img_dict['img'],'Sleeve')
                if predicted_neck_type[0]!=1:
                    pred_patt.append(6)
                    patt=6
                    lab_patt.extend([int(i) for i in img_dict['labels']['pattern']])
                    outputs = model(img_dict['img'],'Only_Sleeve')
                    _, predicted_sleeve_type = torch.max(outputs.data, 1)
                    pred_sleeve.extend([i for i in predicted_sleeve_type])
                    slee=predicted_sleeve_type[0]
                    lab_sleeve.extend([int(i) for i in img_dict['labels']['sleeve_length']])
                    ret=1
            if ret==0:
                pred_sleeve.append(3)
                slee=3
                lab_sleeve.extend([int(i) for i in img_dict['labels']['sleeve_length']])

                outputs = model(img_dict['img'],'Only_Pattern')
                _, predicted_pattern = torch.max(outputs.data, 1)
                pred_patt.extend([i for i in predicted_pattern])
                patt=predicted_pattern[0]
                lab_patt.extend([int(i) for i in img_dict['labels']['pattern']])
            
            total1 += 1#img_dict['labels']['pattern'].size(0)
            total2 += 1#img_dict['labels']['sleeve_length'].size(0)
            total3 += 1#img_dict['labels']['neck_type'].size(0)
            if patt==int(img_dict['labels']['pattern'][0]):
                correct1 += 1#(predicted_pattern == img_dict['labels']['pattern']).sum().item()
            if slee==int(img_dict['labels']['sleeve_length'][0]):
                correct2 += 1#(predicted_sleeve_type == img_dict['labels']['sleeve_length']).sum().item()
            if ne==int(img_dict['labels']['neck_type'][0]):
                correct3 += 1#(predicted_neck_type == img_dict['labels']['neck_type']).sum().item()
            
    print('Accuracy of the network on the '+stri+' images (pattern): %.2d %%' % (100 * correct1 / total1))
    print('Accuracy of the network on the '+stri+' images (sleeve_type): %.2d %%' % (100 * correct2 / total2))
    print('Accuracy of the network on the '+stri+' images (neck_type): %.2d %%' % (100 * correct3 / total3))
    if stri=='test':
        print(np.bincount(pred_patt))
        print(np.bincount(lab_patt))
        cm = confusion_matrix(lab_patt, pred_patt)
        sns.heatmap(cm,annot=True)
        plt.show()
        print(classification_report(lab_patt, pred_patt))
        print(np.bincount(pred_sleeve))
        print(np.bincount(lab_sleeve))
        cm = confusion_matrix(lab_sleeve, pred_sleeve)
        sns.heatmap(cm,annot=True)
        plt.show()
        print(classification_report(lab_sleeve, pred_sleeve))
        print(np.bincount(pred_neck))
        print(np.bincount(lab_neck))
        cm = confusion_matrix(lab_neck, pred_neck)
        sns.heatmap(cm,annot=True)
        plt.show()
        print(classification_report(lab_neck, pred_neck))
    return correct1,correct2,correct3,total1,total2,total3

N_epochs = 50
batch_size = 16
 
model = HierModel()
optimizer = torch.optim.Adam(model.parameters())

def train_epoch(loader,stri,neck_full_labels):
    if len(neck_full_labels)==2:
        weight=[7,1]
    else:
        weight=[11/i for i in np.bincount(neck_full_labels)]
    criterion = nn.CrossEntropyLoss(weight=torch.FloatTensor(weight))
    total_loss = 0
    for i, data in enumerate(loader,0):
        img0, labels = data
        optimizer.zero_grad()
        outputs = model(img0['img'],stri)
        loss = criterion(outputs, img0['labels'])
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    print('Epoch[%d] [%s] loss: %.3f' % (epoch + 1, stri, total_loss))

max_acc1,max_acc2,max_acc3 = 0,0,0
for epoch in range(10):
    train_epoch(train_loader_neck,'Neck',neck_train_y)
    train_epoch(train_loader_only_neck,'Only_Neck',only_neck_train_y)
    train_epoch(train_loader_sleeve,'Sleeve',sleeve_train_y)
    train_epoch(train_loader_only_sleeve,'Only_Sleeve',only_sleeve_train_y)
    train_epoch(train_loader_only_pattern,'Only_Pattern',only_pattern_train_y)

    correct1,correct2,correct3,total1,total2,total3=test_epoch(test_loader,'test')
    correct11,correct21,correct31,total11,total21,total31=test_epoch(train_loader,'train')
    if ((100 * correct1 / total1) > max_acc1 and (100 * correct11 / total11) - (100 * correct1 / total1) <= 20) or ((100 * correct2 / total2) > max_acc2 and (100 * correct21 / total21) - (100 * correct2 / total2) <= 20) or ((100 * correct3 / total3) > max_acc3 and (100 * correct31 / total31) - (100 * correct3 / total3) <= 20):
        max_acc1=(100 * correct1 / total1)
        max_acc2=(100 * correct2 / total2)
        max_acc3=(100 * correct3 / total3)
        torch.save(model.state_dict(), '/content/drive/My Drive/Colab Notebooks/FlixStock/classification-assignment.zip (Unzipped Files)/classification-assignment/Hierarchical.pth')

